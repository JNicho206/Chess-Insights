{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zstandard as zstd\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGE = \"abfss://chessstage@chess-insights.postgre.azure.dfs.core.windows.net:5432/\"\n",
    "PROCESSED = \"abfss://processed@chessinsights.dfs.core.windows.net/\"\n",
    "YEAR_MONTH = datetime.strftime(datetime.now(), \"%Y-%m\")\n",
    "MONTHLY_GAME_FILE = \"lichess_db_standard_rated_{YEAR_MONTH}.pgn.zst\"\n",
    "\n",
    "\n",
    "target = dbutils.widgets.get(\"fileName\")\n",
    "# If this notebook is executed from monthly ETL, no fileName value will be passed\n",
    "target = target if target else MONTHLY_GAME_FILE\n",
    "OUT = PROCESSED + target.split(\".\")[0] + \".parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kv_from_line(line):\n",
    "    if line.startswith('[White \"'):\n",
    "        return \"white_name\", line.split('\"')[1]\n",
    "    elif line.startswith('[Black \"'):\n",
    "        return \"black_name\",  line.split('\"')[1]\n",
    "    elif line.startswith('[UTCDate \"'):\n",
    "        return \"date\", line.split('\"')[1]\n",
    "    elif line.startswith('[WhiteElo \"'):\n",
    "        return \"white_elo\", line.split('\"')[1]\n",
    "    elif line.startswith('[BlackElo \"'):\n",
    "        return \"black_elo\", line.split('\"')[1]\n",
    "    elif line.startswith('[ECO \"'):\n",
    "        return \"eco\", line.split('\"')[1]\n",
    "    elif line.startswith('[Opening \"'):\n",
    "        return \"opening\", line.split('\"')[1]\n",
    "    elif line.startswith('[TimeControl \"'):\n",
    "        return \"time_control\", line.split('\"')[1]\n",
    "    elif line.startswith('[Termination \"'):\n",
    "        return \"termination\", line.split('\"')[1]\n",
    "    # Moves start after metadata, capture them\n",
    "    elif line.startswith('1.'):\n",
    "        return \"moves\", line\n",
    "    else:\n",
    "        return \"outofscope\", None\n",
    "\n",
    "def process_batch(batch):\n",
    "    df = pd.DataFrame(batch)\n",
    "    # Convert white_elo and black_elo to int\n",
    "    df['white_elo'] = pd.to_numeric(df['white_elo'], errors='coerce')\n",
    "    df['white_elo'] = df['white_elo'].fillna(-1).astype('int64')\n",
    "    df['black_elo'] = pd.to_numeric(df['black_elo'], errors='coerce')\n",
    "    df['black_elo'] = df['black_elo'].fillna(-1).astype('int64')\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def write_batch_to_parquet(processed_df, parquet_writer=None, path=OUT):\n",
    "\n",
    "    table = pa.Table.from_pandas(processed_df)\n",
    "    if parquet_writer is None:\n",
    "        parquet_writer = pq.ParquetWriter(path, table.schema)\n",
    "\n",
    "    parquet_writer.write_table(table)\n",
    "\n",
    "    return parquet_writer\n",
    "\n",
    "# Stream decompression and line handling\n",
    "def decompress_and_process_pgn(file_path, batch_size = 10000):\n",
    "\n",
    "    games = []\n",
    "    current_game = {}\n",
    "    parquet_writer = None\n",
    "    batch_n = 1\n",
    "\n",
    "    with open(file_path, 'rb') as compressed_file:\n",
    "        dctx = zstd.ZstdDecompressor()\n",
    "        \n",
    "        # Stream the decompressed content\n",
    "        with dctx.stream_reader(compressed_file) as reader:\n",
    "            buffer = b\"\"  # Accumulate data that doesn't yet form a complete line\n",
    "            \n",
    "            for chunk in iter(lambda: reader.read(65536), b\"\"):\n",
    "                # Add the chunk to the buffer\n",
    "                buffer += chunk\n",
    "                \n",
    "                lines = buffer.split(b'\\n')\n",
    "                \n",
    "                # Process all lines except the last one (which may be incomplete)\n",
    "                for line in lines[:-1]:\n",
    "                    if line.strip() == b\"\":  # Skip empty lines\n",
    "                        continue\n",
    "\n",
    "                    key, value = extract_kv_from_line(line.decode('utf-8').strip())  # Process each line\n",
    "\n",
    "                    if key == \"outofscope\":\n",
    "                        continue\n",
    "\n",
    "                    current_game[key] = value\n",
    "                    if key == \"moves\": # end of game info\n",
    "                        games.append(current_game)\n",
    "                        current_game = {}\n",
    "                        if len(games) == batch_size:\n",
    "                            processed_batch = process_batch(games)\n",
    "                            games.clear()\n",
    "                            parquet_writer = write_batch_to_parquet(processed_batch, parquet_writer, path=\"./2015-08.parquet\")\n",
    "                            print(f\"Processed batch {batch_n}\")\n",
    "                            batch_n += 1\n",
    "\n",
    "\n",
    "                # Save the last line (incomplete) to the buffer for the next chunk\n",
    "                buffer = lines[-1]\n",
    "\n",
    "        # After the loop, process any remaining buffer data\n",
    "        if buffer:\n",
    "            if buffer.strip() != b\"\":  # Skip empty lines\n",
    "                key, value = extract_kv_from_line(buffer.decode('utf-8').strip())\n",
    "                if key != \"moves\": # Skip incomplete games\n",
    "                    pass\n",
    "                else:\n",
    "                    current_game[key] = value\n",
    "                    games.append(current_game)\n",
    "                    current_game = {}\n",
    "        if games:\n",
    "            processed_batch = process_batch(games)\n",
    "            parquet_writer = write_batch_to_parquet(processed_batch, parquet_writer, path=\"./2015-08.parquet\")\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompress_and_process_pgn(target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
